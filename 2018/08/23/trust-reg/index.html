<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><meta name="google-site-verification" content="9rI-R9CaRiMYlQ9aB6hFKjKp9cwmAm3TeV2szbNzuoI"><meta name="baidu-site-verification" content="qmVEp0OVpw"><title>置信域算法 | 西部世界</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">置信域算法</h1><a id="logo" href="/.">西部世界</a><p class="description">西蒙的个人博客</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">置信域算法</h1><div class="post-meta">Aug 23, 2018<span> | </span><span class="category"><a href="/categories/技术/">技术</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 443</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 2</span><span class="post-meta-item-text"> 分钟</span></span></span></div><a class="disqus-comment-count" href="/2018/08/23/trust-reg/#vcomment"><span class="valine-comment-count" data-xid="/2018/08/23/trust-reg/"></span><span> 条评论</span></a><div class="post-content"><h2 id="1-什么是Trust-Region？"><a href="#1-什么是Trust-Region？" class="headerlink" title="1.什么是Trust Region？"></a>1.什么是Trust Region？</h2><p>Trust Region和Line Search是两个最基本的最优化算法。</p>
<ol>
<li>Line Search：“先方向，后步长”，即先寻找正确的更新方向（比如梯度的负方向），再寻找最合适和步长$\alpha$</li>
<li>Trust Region：“先步长，后方向”，即先选取一个可信赖的区域，然后在区域内求解近似模型的最优解，在此基础上增量迭代。</li>
</ol>
<h2 id="2-Trust-Region算法流程"><a href="#2-Trust-Region算法流程" class="headerlink" title="2.Trust Region算法流程"></a>2.Trust Region算法流程</h2><ol>
<li>基于当前位置$x_i$，给定一个可信赖区域$\Omega = \lbrace x|\; \parallel x - x_i\parallel \leq R\rbrace$，$R$是区域半径。</li>
<li>在$x_i$处构造原函数$f(x)$的近似函数$\hat{f}(p) \approx f(x+p)$（通常是泰勒二阶近似）。</li>
<li>求最优解得到试探步长：$$p_i = \arg\min \limits_{p} \hat{f}(p), \; s.t. \parallel p\parallel \leq R$$</li>
<li><p>计算$r_i$：$$r_i = \frac{f(x_i) - f(x_i + p_i)}{\hat{f}(0) - \hat{f}(p_i)}$$<br> a. 若$r_i \geq 0.75$，说明近似效果好，则可以适当增加$R = 2R$并重新计算$p_i$；<br> b. 若$0.25 &lt; r_i &lt; 0.75$，保持$R$不变，并认为步长$p_i$是可靠的；<br> c. 若$r_i \leq 0.25$，说明近似效果很差，则减小$R = \frac{||p_i||}{4}$并重新计算$p_i$；</p>
</li>
<li><p>循环上述步骤，直到达到任意结束条件：<br> a. 达到最大迭代次数<br> b. $\Delta x$小于阈值<br> c. 下降梯度小于阈值</p>
</li>
</ol>
<p>置信域是一种很重要的算法，强化学习中的TRPO以及PPO算法都是基于置信域理论，后期会单独聊一下这两个算法。前几天鹅厂竟然邀请到了Pieter Abbeel来做分享会，有幸听到了Pieter Abbeel对元学习、模仿学习、强化学习的一些见解和研究，简直激动，有机会也会整理出来。</p>
</div><iframe src="/donate/?AliPayQR=/img/AliPayQR.png&amp;WeChatQR=/img/WeChatQR.png&amp;GitHub=https://github.com/cheersyouran&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>ZHANG Youran</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2018/08/23/trust-reg/">https://cheersyouran.github.io/2018/08/23/trust-reg/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>版权归作者所有，转载请注明出处。</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://cheersyouran.github.io/2018/08/23/trust-reg/" data-id="cjz3uecxr0006o5vrxmcx1lxi" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACOElEQVR42u3aSY6EQAwF0br/pWmpV71okvhOKAk7WJUohnwsLA/5+eDj+D3WZ/6eP/uXvKV2rwwZMnozjuWxXjRZCvm9vne9NhkyZMxhrIPs+hHkNeslkk9wsWYZMmTIWAZcEmT5GRkyZMjYD7i8xOXBlKePMmTImMwgRWztfK1X9mAtLkOGjBcy0sHAN38/ON+QIUPGSxhHeKyDKQ+LaWC9WJUMGTJaM2obKUjhWgPwVt0N+0FkyJDxKkatXOSM9DPx62XIkDGBUWtd8UKUJ5So9X/2HBkyZLRmpM19MqqsbcLgAfr0ShkyZAxgpOlj2iarPYcPO2XIkNGb8cQGr3QkWSuJZciQMYFx73iydr6WJp5OYmXIkDGAkT6Ut+TW9/Jr/rlehgwZrRnpEDEdTKYfIm20yZAhYw6DJHx8EWnQ3Clugz6cDBkyXsvYSf5IccsjPS+SUYYrQ4aMMQzy4p3BZK2EDrqGMmTIaMHYXzoPxLxY5UmkDBkyZjJ2GnBpWcsTU7RpTIYMGU0ZPGnjy02Xno4qg36hDBkyGjHSQrQ27NzZLnZBkiFDRmsGLylrQ8egWRYWxjJkyJjDOMJjvxCtJZoXz5EhQ0ZrRhrs+CCBDy9vSw1lyJDRmkGC7F1bx/YDbjA1lSFDRjsGb9ATHm+61YJ+sNlChgwZwxjpFgqS9qXhPhhkypAhYzCD3LUz+EzxMmTImMNIG2Qcdu+g9DTcy5AhozXjrl5WrTGXJoVbGBkyZLyP8QMy27wqTU0zmgAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="/tags/凸优化/">凸优化</a></div><div class="post-nav"><a class="pre" href="/2018/08/28/trpo/">TRPO</a><a class="next" href="/2018/08/16/cons-ops/">约束优化</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'bniJ3zoUdRvlPtkBwpdn3cgB-gzGzoHsz',
  appKey:'39V42UT82heESUV7ROEM2YH0',
  placeholder:'请在此输入留言，一起交流进步~',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a><span class="category-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Alphago/" style="font-size: 15px;">Alphago</a> <a href="/tags/强化学习/" style="font-size: 15px;">强化学习</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/凸优化/" style="font-size: 15px;">凸优化</a> <a href="/tags/策略梯度/" style="font-size: 15px;">策略梯度</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/08/28/trpo/">TRPO</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/23/trust-reg/">置信域算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/cons-ops/">约束优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/19/alphago/">Alphago的原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/17/pg/">强化学习——从随机策略梯度到确定性策略梯度</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">西部世界.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>