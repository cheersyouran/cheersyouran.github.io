<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><meta name="google-site-verification" content="9rI-R9CaRiMYlQ9aB6hFKjKp9cwmAm3TeV2szbNzuoI"><meta name="baidu-site-verification" content="qmVEp0OVpw"><title>约束优化 | 西部世界</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">约束优化</h1><a id="logo" href="/.">西部世界</a><p class="description">西蒙的个人博客</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">约束优化</h1><div class="post-meta">Aug 16, 2018<span> | </span><span class="category"><a href="/categories/技术/">技术</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2,156</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 10</span><span class="post-meta-item-text"> 分钟</span></span></span></div><a class="disqus-comment-count" href="/2018/08/16/cons-ops/#vcomment"><span class="valine-comment-count" data-xid="/2018/08/16/cons-ops/"></span><span> 条评论</span></a><div class="post-content"><h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>这几天碰到一个业务，问题的目标不仅仅是提高CVR，而是既保证CVR又要保证广告分发的结构。一开始以为是一个约束优化问题，但仔细思考了一下，发现并不是，因为这里的约束不是已知变量x而是y，无奈只能采用别的方法。<br>回归本文主题，我也算是借这个机会回顾了一下优化论的东西，所以在这里做一个简单的总结和整理。</p>
<h2 id="1-优化问题分类"><a href="#1-优化问题分类" class="headerlink" title="1. 优化问题分类"></a>1. 优化问题分类</h2><p>首先，优化问题分为以下三种：</p>
<ol>
<li>无约束光滑优化：主要采用梯度下降的方法进行求解</li>
<li>无约束非光滑优化：主要采用次梯度下降的方法进行求解</li>
<li>有约束优化：主要采用投影梯度下降，ADMM，Uzawa等算法</li>
</ol>
<p>本文主要针对有约束优化做一下讨论。</p>
<h2 id="2-SVM中的约束优化问题"><a href="#2-SVM中的约束优化问题" class="headerlink" title="2. SVM中的约束优化问题"></a>2. SVM中的约束优化问题</h2><p>首先简单推导一下SVM。假设两个支持向量点$x_1$ 和 $x_2$分别在如下两条边界线上：<br>\begin{equation}<br>\begin{cases}<br>&lt;w ,x_1&gt; +\;b = 1, &amp;(2.1)\\<br>&lt;w ,x_1&gt; +\;b = -1, &amp;(2.2)<br>\end{cases}<br>\end{equation}根据$x_1$和$x_2$的连线与法向量平行，可得公式(2.3)；公式(2.1)(2.2)相减可得(2.4)：<br>\begin{equation}<br>\begin{cases}<br>x_1 - x_2 = C · w， &amp;\quad (2.3)\\<br>&lt;w ,x_1 - x_2&gt;\;= 2, &amp;\quad (2.4)<br>\end{cases}<br>\end{equation}结合(3)，(4)两项我们得到：$$C=\frac{2}{\parallel w\,\parallel^2_2}$$$margin = \parallel x_1 - x_2\,\parallel$，我们的目标是margin最大化，即$max \parallel x_1 - x_2\parallel_2 = |C|·\parallel  x\parallel_2 = \frac{2}{\parallel w\parallel_2}$，<br>将最大化问题转化为于最小化，我们就得到了目标的不等式约束优化问题：<br>\begin{equation}<br>\begin{cases}<br>\min　\frac{1}{2}\parallel w\,\parallel^2\\<br>s.t.　y_i(&lt;w,x_i&gt; +\;b)\geq 1, \quad i=1,2,…,m;<br>\end{cases}<br>\quad (2.5)<br>\end{equation}这里，我们采用拉格朗日乘子法求解不等式约束优化问题。<br>首先构造拉格朗日函数：$$L(w,b,\lambda)=\frac{1}{2}\parallel w \parallel^2 + \sum^m_{i=1}\lambda_i[1−y_i(w^Tx_i+b)]\quad (2.6)$$则我们的原问题表示为如下(推导过程略，有空再补上)：$$\min \limits_{w,b} \max \limits_{\lambda} L(w,b,\lambda)$$这个公式又称为<em>Primal Problem</em>。<br>对应的，还有一个公式称为<em>Dual Problem</em>，公式如下：$$\max \limits_{\lambda} \min \limits_{w,b} L(w,b,\lambda)$$当满足slater condition时，强对偶性成立，也就是说此时Primal和Dual是等价的。此时，我们就可以通过求解Dual Problem问题来求解Primal Problem。当我们得到Dual Problem的解$\lambda^*$，通过KKT条件可得到Primal Problem的解$w^*, b^*$。</p>
<p>首先求解对偶问题中的$\min \limits_{w,b} L(w,b,\alpha)$，分别令$L(w,b,\alpha)$对$w, b$的导数为0：<br>\begin{equation}<br>\begin{cases}<br>\frac{\partial L(w,b,\lambda)}{\partial w} = w - \sum_{i=1}^{m}\lambda_i y_i x_i = 0, &amp;(2.7)\\<br>\frac{\partial L(w,b,\lambda)}{\partial b} = \sum_{i=1}^{m}\lambda_i y_i= 0, &amp;(2.8)\\<br>\end{cases}<br>\end{equation}将公式(2.7)，(2.8)带入$\min \limits_{w,b} L(w,b,\lambda)$中化简得到：<br>$$\min \limits_{w,b} L(w,b,\lambda) = - \sum_{i=1}^{m} \lambda_i + \frac{1}{2}\sum_{i=1}^{m} \sum_{j=1}^{m} \lambda_i \lambda_j y_i y_j x_i^T x_j $$最终我们将对偶问题$\max \limits_{\lambda} \min \limits_{w,b} L(w,b,\lambda)$转化为如下公式：<br>\begin{equation}<br>\begin{cases}<br>\max \limits_{\lambda} \sum_{i=1}^{m} \lambda_i - \frac{1}{2}\sum_{i=1}^{m} \sum_{j=1}^{m} \lambda_i \lambda_j y_i y_j x_i^T x_j \\<br>s.t.\quad \sum_{i=1}^{m}\lambda_i y_i= 0\\<br>\quad\quad\;\;\lambda_i \geq 0<br>\end{cases}<br>\quad (2.9)<br>\end{equation}</p>
<p>现在，我们已经将svm约束问题(2.5)转化成为了新的约束问题(2.9)，转化后的问题只包含一类变量$\lambda$，我们可以用任意一种二次优化方法求解，其中一种比较高效的算法叫SMO，当然，也可以用PGD方法来求解，下一节会讲到PDG方法。(关于SMO算法，我会在单独写一篇博文来详细介绍)。求出了对偶问题的最优解$\lambda^*$，根据KKT条件，我们就可以得到原问题的解了。</p>
<h2 id="3-投影梯度下降法（Projected-Gradient-Descend）"><a href="#3-投影梯度下降法（Projected-Gradient-Descend）" class="headerlink" title="3. 投影梯度下降法（Projected Gradient Descend）"></a>3. 投影梯度下降法（Projected Gradient Descend）</h2><p>定义如下Indicator函数：<br>\begin{equation}<br>I_s(x) =<br>\begin{cases}<br>0 &amp;if\quad x \in S\\<br>+\infty &amp;if\quad x \notin S<br>\end{cases}<br>\end{equation}则约束优化$$\min \limits_{x \in \mathbb R^n} f(x) \quad s.t. \; x \in S $$ 可以改写为如下形式：$$\min \limits_{x \in \mathbb R^n} f(x) + I_s(x), \quad (3.1)$$从公式(3.1)我们可以看出，第一项$f(x)$是一个光滑凸函数，第二项$I_s(x)$是一个非光滑凸函数。这样，我们就把约束问题转换成了无约束问题，可以方便的应用forward-backward splitting(FBS)算法求解。<br>FBS算法如下（FBS本质来自于次梯度下降，会另起一篇文章介绍）：$$ x^{(k+1)} = prox_{\alpha g}(x^{(k)} - \alpha_k \nabla f(x^{(k)})),$$$$其中，prox_{\alpha g}(y) = \arg\min \limits_{x \in \mathbb R^n} \frac{1}{2} ||x - y||^2 + \alpha g(x) $$当$g(x) = I_s(x)$时，此时的FBS算法又叫投影梯度下降算法：<br>\begin{equation}<br>\begin{split}<br>P_s(y) &amp;= prox_{\alpha I}(x^{(k)})(y)\\<br>&amp;= \arg\min \limits_{x \in \mathbb R^n} \frac{1}{2} ||x - y||^2 + \alpha I(x) \\<br>&amp;= \arg\min \limits_{x \in S} \frac{1}{2} ||x - y||^2<br>\end{split}<br>\end{equation}则最终的投影梯度更新方程如下：<br>$$x^{(k+1)} = P_{s}(x^{(k)} - \alpha_k \nabla f(x^{(k)})$$<strong>以刚才的SVM对偶问题为例</strong>，我们可以用PGD来求解。<br>定义矩阵$K \in \mathbb R^{m \times n}$，其中$K_{i,j} = y_i y_j x_i^T x_j, $，则对偶问题可以改写为：<br>\begin{equation}<br>\begin{cases}<br>\max \limits_{\lambda} -\frac{1}{2} \lambda^T K \lambda + \lambda^T 1\\<br>s.t. \quad \lambda \geq 0\\<br>\quad \quad \;\; \lambda^Tb = 0<br>\end{cases}<br>\end{equation}我们将投影域表示为$ S \in \lbrace \lambda | \lambda \geq 0, \lambda^Tb = 0\rbrace $<br>对于$ \forall \mu \in \mathbb R^m $，$$ P_s(\mu) = \arg\min \limits_{\lambda \in S} \frac{1}{2} ||\lambda - \mu||^2 $$对于这个约束优化函数，我们可以构造拉格朗日函数求解：$$ L(\lambda, \alpha, \beta) = \frac{1}{2}||\lambda - \mu||^2_2 + \lambda^T\alpha + \beta \lambda^T b $$对偶函数：$$ \max \limits_{\alpha \leq 0, \beta} \min \limits_{\lambda} \frac{1}{2}||\lambda - \mu||^2_2 + \lambda^T\alpha + \beta \lambda^T b （3.2）$$ 对 $ \min \limits_{\lambda} $求导，得到$ \lambda = (\mu - \beta b) - \alpha $带入（3.2）中，得到<br>\begin{equation}<br>\begin{split}<br>&amp;\max \limits_{\alpha \leq 0, \beta} -\frac{1}{2} ||\alpha + \beta b - \mu ||^2_2\\<br>= &amp;\min \limits_{\beta} \min \limits_{\alpha \leq 0}\frac{1}{2} ||\alpha + \beta b - \mu ||^2_2（3.3）<br>\end{split}<br>\end{equation}对于（3.3）中的$\min \limits_{\alpha \leq 0}$项，我们容易求得$\alpha = (\mu - \beta b)_{-}$，最终公式（3.2）转换为一个单变量优化问题：</p>
<p>\begin{equation}<br>\begin{split}<br>\min \limits_{\beta} \frac{1}{2}||(\mu - \beta b)_{+}||^2_2<br>\end{split}<br>\end{equation}求出对偶问题的最优解$\alpha^*$和$\beta^*$后，再根据KKT条件，即可求出原问题的最优解$\lambda^*$。</p>
<p>最终，SVM对偶问题的PDG求解公式如下：</p>
<p>\begin{equation}<br>\begin{split}<br>\lambda^{(k+1)} = P_s(\lambda^{(k)} - \delta_k(K \lambda^{(k)} - 1))<br>\end{split}<br>\end{equation}</p>
<p>\begin{equation}<br>\begin{split}<br>其中，P_s(\mu) = (\mu - \beta b)_{+}，<br>\end{split}<br>\end{equation}</p>
<p>$$\beta = \arg \min \limits_{\beta} \frac{1}{2} ||(\mu - \beta b )_{+}||^2_2$$</p>
<h2 id="4-Uzawa算法"><a href="#4-Uzawa算法" class="headerlink" title="4. Uzawa算法"></a>4. Uzawa算法</h2><p>PGD是一个非常重要的算法。由上面的介绍我们知道，PGD面向原问题$f(x)$，先按梯度方向更新$x$，然后把更新后的$x$在其自己的约束域上投影。而有些时候，对偶问题$d(\lambda, \mu)$是个光滑函数，$\lambda, \mu$的约束也十分简单，更方便求解投影。这个算法就叫Uzawa算法。 </p>
<p>\begin{equation}<br>\begin{cases}<br>\min \limits_{x \in \mathbb R^n}&amp; f(x)\\<br>s.t. &amp;g_i(x) \leq 0, i = 1,2,…,p\\<br>&amp;h_i(x) = 0, i = 1,2,…,q<br>\end{cases}<br>\end{equation}</p>
<p>算法形式如下：<br>\begin{equation}<br>\begin{cases}<br>x^{(k+1)} = \arg \min \limits_{x \in \mathbb R^n} L(x, \lambda^{(k)}, \mu^{(k)})\\<br>\lambda^{(k+1)}_i = (\lambda^{(k)}_i + \alpha_k g_i(x^{(k+1)}))_{+}, for i=1,2,…,p\\<br>\mu^{(k+1)}_i = \mu^{(k)}_i + \alpha_k h_i(x^{(k+1)}), for i=1,2,…,q\\<br>\end{cases}<br>\end{equation}</p>
<h2 id="5-ADMM算法"><a href="#5-ADMM算法" class="headerlink" title="5. ADMM算法"></a>5. ADMM算法</h2><p>Uzawa和PGD算法中，约束的形式通常是不等式约束，他们对于下述问题可能不方便求解：<br>\begin{equation}<br>\begin{cases}<br>\min \limits_{x, y} f(x) + g(y)\\<br>s.t. Ax - y = 0<br>\end{cases}<br>\end{equation}<br>或者有时候，我们可以把无约束问题转化为有约束问题，更方便求解，如：<br>\begin{equation}<br>\min \limits_{x} f(x) + g(Ax) =&gt;<br>\begin{cases}<br>\min \limits_{x, y} f(x) + g(y)\\<br>s.t. Ax - y = 0<br>\end{cases}<br>\end{equation}<br>以上问题可以尝试使用ADMM算法求解。求解过程如下：</p>
<ol>
<li>构造增广拉格朗日函数（Augmented Lagrangian Function）$$L_{\gamma}(x, y, \mu) = f(x) + g(y) + \mu^T(Ax - y) + \frac{\gamma}{2} ||Ax - y||^2_2$$</li>
<li>迭代计算：<br>\begin{equation}<br>\begin{cases}<br>x^{(k+1) = \arg\min\limits_{x} L_{\gamma}(,x, y^{(k)}), \mu^{(k)}}\\<br>y^{(k+1) = \arg\min\limits_{y} L_{\gamma}(,x^{(k+1)}, y, \mu^{(k)}}\\<br>\mu^{(k+1)} = \mu^{(k)} + \alpha_k(Ax^{(k+1)} - y^{(k+1)})<br>\end{cases}<br>\end{equation}</li>
</ol>
</div><iframe src="/donate/?AliPayQR=/img/AliPayQR.png&amp;WeChatQR=/img/WeChatQR.png&amp;GitHub=https://github.com/cheersyouran&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>ZHANG Youran</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2018/08/16/cons-ops/">https://cheersyouran.github.io/2018/08/16/cons-ops/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>版权归作者所有，转载请注明出处。</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://cheersyouran.github.io/2018/08/16/cons-ops/" data-id="cjz3uecxl0002o5vr1npbdydr" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACLklEQVR42u3aQW7CQAwFUO5/6VTqCqkNfNuhamberJAIiV8Wxh7P4xGv43s9f35eZ9f//PaI1+MTCwMD47aM5Havb30WbvLb19cXqBgYGBswqreeZMIe6U3MGBgYGEE6LjzyZRGJgYGBMU+4SZtaTbvVkhQDA2NPRp5S89CTlJpceXEvjoGBcUNGbzDwN58/Pt/AwMD494yjtapB5EmzGQ8GBsbSjGSzbHKQYjIorY5RMTAwVmXkB7x6b6jX3ObN6un/BgYGxkKMfFM+P/g1GXyOxqIYGBiLMuYHwuahzAcGGBgYOzCqwVXLu2ZvnXepGBgYSzOSyjEPsbeFlx+tyFM5BgbGSoxeWM0C7tKUioGBsQ9jkgTz0PPyMRl5FspKDAyM5RjVQWbvgEU+4KzCMDAwVmXkDWTvwb2DF/lYotwHY2Bg3JYx2ayvNqvVEWkUFQYGxmaMXvrLG9H5yOGXO2BgYGzD6IWVpNrkNY1eJQYGxtKM/IhDdTxZpSbl5pt7YmBgbMBImsY8CZaDCLrR8n4eBgbGcoyrjoL1XscFY04MDIylGXlKTR5T/e1kqICBgbEDo9e+VtNutfirFqAYGBhrM6q1Vq9wzAOtDkoxMDD2YeRjgHzrf5Kmm8NRDAyMDRi9dJln8d5QM2mPMTAwMKoJt3fILD94cYrHwMDAiIvFaq9cbVkxMDB2ZuRN6ST5TlLqm5eCgYGxNKM6GMgLwWpxWW1lR/MNDAyMezC+ALMkk2FqJ1ypAAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/凸优化/">凸优化</a></div><div class="post-nav"><a class="pre" href="/2018/08/23/trust-reg/">置信域算法</a><a class="next" href="/2018/06/19/alphago/">Alphago的原理</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'bniJ3zoUdRvlPtkBwpdn3cgB-gzGzoHsz',
  appKey:'39V42UT82heESUV7ROEM2YH0',
  placeholder:'请在此输入留言，一起交流进步~',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a><span class="category-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Alphago/" style="font-size: 15px;">Alphago</a> <a href="/tags/强化学习/" style="font-size: 15px;">强化学习</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/凸优化/" style="font-size: 15px;">凸优化</a> <a href="/tags/策略梯度/" style="font-size: 15px;">策略梯度</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/08/28/trpo/">TRPO</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/23/trust-reg/">置信域算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/cons-ops/">约束优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/19/alphago/">Alphago的原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/17/pg/">强化学习——从随机策略梯度到确定性策略梯度</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">西部世界.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>